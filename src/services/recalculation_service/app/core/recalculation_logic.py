# src/services/recalculation_service/app/core/recalculation_logic.py
import logging
from datetime import date
from typing import Optional
from sqlalchemy.ext.asyncio import AsyncSession

from portfolio_common.kafka_utils import get_kafka_producer
from portfolio_common.events import TransactionEvent
from portfolio_common.config import KAFKA_RAW_TRANSACTIONS_COMPLETED_TOPIC
from portfolio_common.logging_utils import correlation_id_var
from ..repositories.recalculation_repository import RecalculationRepository

logger = logging.getLogger(__name__)

class RecalculationLogic:
    """
    Orchestrates the recalculation process by cleaning stale downstream data
    and re-publishing the raw transaction events to trigger the pipeline again.
    """
    @staticmethod
    async def execute(
        db_session: AsyncSession,
        job_id: int,
        portfolio_id: str,
        security_id: str,
        from_date: date,
        correlation_id: Optional[str]
    ) -> None:
        """
        Executes the full recalculation flow for a given portfolio/security pair.
        
        1. Deletes all downstream calculated data from the `from_date` onwards.
        2. Fetches all transactions for the security from the beginning of time.
        3. Republishes the 'raw_transactions_completed' event for each transaction
           in chronological order to trigger the entire pipeline again.
        """
        repo = RecalculationRepository(db_session)
        kafka_producer = get_kafka_producer()
        
        headers = []
        if correlation_id:
            headers.append(('correlation_id', correlation_id.encode('utf-8')))
        headers.append(('recalculation_id', str(job_id).encode('utf-8')))


        # Step 1: Clean up all downstream data generated by previous calculations
        await repo.delete_downstream_data(portfolio_id, security_id, from_date)
        
        # Step 2: Fetch all transactions for the security to ensure complete history is replayed
        all_transactions = await repo.get_all_transactions_for_security(portfolio_id, security_id)

        if not all_transactions:
            logger.warning(
                "No transactions found for security during recalculation. Cleanup was performed, but no events were republished.",
                extra={"portfolio_id": portfolio_id, "security_id": security_id}
            )
            return

        # Step 3: Republish events to trigger the pipeline again
        logger.info(
            f"Republishing {len(all_transactions)} transaction events to trigger recalculation.",
            extra={"portfolio_id": portfolio_id, "security_id": security_id}
        )
        
        for txn in all_transactions:
            event_to_publish = TransactionEvent.model_validate(txn)
            
            kafka_producer.publish_message(
                topic=KAFKA_RAW_TRANSACTIONS_COMPLETED_TOPIC,
                key=txn.portfolio_id,
                value=event_to_publish.model_dump(mode='json'),
                headers=headers
            )
        
        kafka_producer.flush()